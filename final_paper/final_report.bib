% This file was created with JabRef 2.5.
% Encoding: ISO8859_1

@INPROCEEDINGS{bagnell12integrated,
  author = {J. Andrew Bagnell and Felipe Cavalcanti and Lei Cui and Thomas Galluzzo and Martial Hebert and Moslem Kazemi and Matthew Klingensmith and Jacqueline Libby and Tian Yu Liu and Nancy Pollard and Mikhail Pivtoraiko and Jean-Sebastien Valois and Ranqi Zhu},
  title = {An integrated system for autonomous robotics manipulation},
  booktitle = {Intelligent Robots and Systems Conference},
  year = {2012}
}

@ARTICLE{calinon13compliant,
  author = {Sylvain Calinon and Petar Kormushev and Darwin G. Caldwell},
  title = {Compliant skills acquisition and multi-optima policy search with EM-based reinforcement learning},
  journal = {Robotics and Autonomous Systems},
  year = {2013},
  volume = {61},
  number = {4},
  pages = {369-379}
}

@INPROCEEDINGS{chrisman92reinforcement,
  author = {Lonnie Chrisman},
  title = {Reinforcement Learning with Perceptual Aliasing: The Perceptual Distinctions Approach},
  booktitle = {In Proceedings of the Tenth National Conference on Artificial Intelligence},
  year = {1992},
  pages = {183--188},
  publisher = {AAAI Press}
}

@INPROCEEDINGS{daniel12learning,
  author = {Daniel, C. and Neumann, G. and Peters, J.},
  title = {Learning Concurrent Motor Skills in Versatile Solution Spaces},
  booktitle = {Proceedings of the International Conference on Robot Systems (IROS)},
  year = {2012},
  file = {daniel12learning.pdf:unsorted/daniel12learning.pdf:PDF}
}

@INPROCEEDINGS{dey12contextual,
  author = {Debadeepta Dey AND Tian Yu Liu AND Martial Hebert AND J. Andrew Bagnell},
  title = {Contextual Sequence Prediction with Application to Control Library Optimization},
  booktitle = {Proceedings of Robotics: Science and Systems},
  year = {2012},
  address = {Sydney, Australia},
  month = {July},
  file = {dey12contextual.pdf:unsorted/dey12contextual.pdf:PDF}
}

@INPROCEEDINGS{kober10reinforcement,
  author = {J. Kober and E. Oztop and J. Peters},
  title = {Reinforcement Learning to adjust Robot Movements to New Situations},
  booktitle = {Proceedings of Robotics: Science and Systems},
  year = {2010},
  address = {Zaragoza, Spain},
  month = {June},
  file = {:home/stulp/docs/bibliography/robotics/reinforcement-learning/kober10reinforcement.pdf:PDF},
  keywords = {reinforcement learning, meta-parameters}
}

@INPROCEEDINGS{kupcsik13dataefficient,
  author = {Kupcsik, A.G. and Deisenroth, M.P. and Peters, J. and Neumann, G.},
  title = {Data-Efficient Generalization of Robot Skills with Contextual Policy Search},
  booktitle = {Proceedings of the National Conference on Artificial Intelligence (AAAI) },
  year = {2013},
  file = {kupcsik13dataefficient.pdf:unsorted/kupcsik13dataefficient.pdf:PDF}
}

@INPROCEEDINGS{marin12towards,
  author = {Marin, D. and Sigaud, O.},
  title = {Towards fast and adaptive optimal control policies for robots: A direct policy search approach},
  booktitle = {Proceedings Robotica},
  year = {2012},
  pages = {21-26},
  address = {Guimaraes, Portugal}
}

@ARTICLE{matsubara11learning,
  author = {Matsubara, T and Hyon, S and Morimoto, J},
  title = {Learning parametric dynamic movement primitives from multiple demonstrations},
  journal = {Neural Networks},
  year = {2011},
  volume = {24},
  number = {5},
  pages = {493-500},
  file = {matsubara11learning.pdf:unsorted/matsubara11learning.pdf:PDF}
}

@INPROCEEDINGS{mccallum95instancebased,
  author = {R. Andrew Mccallum},
  title = {Instance-Based Utile Distinctions for Reinforcement Learning with Hidden State},
  booktitle = {In Proceedings of the Twelfth International Conference on Machine Learning},
  year = {1995},
  pages = {387--395},
  publisher = {Morgan Kaufmann}
}

@ARTICLE{piater11learning,
  author = {Piater, Justus and Jodogne, S{\'e}bastien and Detry, Renaud and Kraft, Dirk and Kr\"{u}ger, Norbert and Kroemer, Oliver and Peters, Jan},
  title = {Learning visual representations for perception-action systems},
  journal = {Int. J. Rob. Res.},
  year = {2011},
  volume = {30},
  number = {3},
  month = mar,
  pages = {294--307},
  acmid = {1945947},
  address = {Thousand Oaks, CA, USA},
  doi = {10.1177/0278364910382464},
  file = {piater11learning.pdf:unsorted/piater11learning.pdf:PDF},
  issn = {0278-3649},
  issue_date = {March 2011},
  keywords = {Autonomous agents, cognitive robotics, computer vision, grasping,
	learning and adaptive systems, manipulation, sensing and perception},
  numpages = {14},
  publisher = {Sage Publications, Inc.},
  url = {http://dx.doi.org/10.1177/0278364910382464}
}

@INPROCEEDINGS{silva12learning,
  author = {Bruno Da Silva and George Konidaris and Andrew Barto},
  title = {Learning Parameterized Skills},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML-12)},
  year = {2012},
  editor = {John Langford and Joelle Pineau},
  series = {ICML '12},
  pages = {1679--1686},
  address = {New York, NY, USA},
  month = {July},
  publisher = {Omnipress},
  file = {silva12learning.pdf:unsorted/silva12learning.pdf:PDF},
  isbn = {978-1-4503-1285-1},
  keywords = {manifolds, meta-parameters},
  location = {Edinburgh, Scotland, GB},
  review = {1) train K DMPs on K trajectories
	
	2) learn D lower-dimensional surfaces (ISOMAP)
	
	3) train a classifier that maps from T to which of the D surfaces
	
	4) compute a regression from T to each policy parameter individually
	for each of the D surfaces (SVM)}
}

@INPROCEEDINGS{stulp13learning,
  author = {Freek Stulp and Gennaro Raiola and Antoine Hoarau and Serena Ivaldi and Olivier Sigaud},
  title = {Learning Compact Parameterized Skills with Expanded Function Approximators},
  booktitle = {submitted to IEEE-RAS International Conference on Humanoid Robots},
  year = {2013}
}

@ARTICLE{stulp12reinforcement,
  author = {Freek Stulp and Evangelos Theodorou and Stefan Schaal},
  title = {Reinforcement Learning with Sequences of Motion Primitives for Robust Manipulation},
  journal = {IEEE Transactions on Robotics},
  year = {2012},
  volume = {28},
  number = {6},
  note = {King-Sun Fu Best Paper Award of the IEEE Transactions on Robotics
	for the year 2012},
  pages = {1360-1370},
  abstract = {Physical contact events often allow a natural decomposition of manipulation
	tasks into action phases and subgoals. Within the motion primitive
	paradigm, each action phase corresponds to a motion primitive, and
	the subgoals correspond to the goal parameters of these primitives.
	Current state-of-the-art reinforcement learning algorithms are able
	to efficiently and robustly optimize the parameters of motion primitives
	in very high-dimensional problems. These algorithms often consider
	only shape parameters, which determine the trajectory between the
	start- and end-point of the movement. In manipulation, however, it
	is also crucial to optimize the goal parameters, which represent
	the subgoals between the motion primitives. We therefore extend the
	policy improvement with path integrals (PI$^2$) algorithm to simultaneously
	optimize shape and goal parameters. Applying simultaneous shape and
	goal learning to sequences of motion primitives leads to the novel
	algorithm PI$^2$-Seq. We use our methods to address a fundamental
	challenge in manipulation: improving the robustness of everyday pick-and-place
	tasks.},
  bib2html_pubtype = {Journal,Awards},
  bib2html_rescat = {Reinforcement Learning of Robot Skills}
}

@ARTICLE{ude10taskspecific,
  author = {Ales Ude and Andrej Gams and Tamim Asfour and Jun Morimoto},
  title = {Task-Specific Generalization of Discrete and Periodic Dynamic Movement Primitives},
  journal = {IEEE Transactions on Robotics},
  year = {2010},
  volume = {26},
  number = {5},
  pages = {800-815},
  file = {:/home/stulp/docs/bibliography/robotics/unsorted/Ude, Gams, Asfour, Morimoto - 2010 - Task Specific Generalization of Discrete and Periodic Dynamic Movement Primitives.pdf:PDF},
  keywords = {meta-parameters}
}

